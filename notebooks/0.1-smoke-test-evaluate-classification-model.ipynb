{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "\n",
    "# Import my libs\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.models.binary_classification.evaluate.pr_curve import plot_iso_f_beta, plot_pr_curve\n",
    "from src.models.binary_classification.evaluate.metrics import metric_pr_auc, metric_pr_f_beta, get_threshold_best_pr_fbeta\n",
    "from utils import altair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmokeTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.choice([0, 1], size=1000, p=[.9, .1])\n",
    "probs = np.random.uniform(low=0.0, high=1.0, size=1000)\n",
    "\n",
    "pd.DataFrame({\"y\": y, \"probs\": probs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance calculation (F-1 score, AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y, probs)\n",
    "pr = pd.DataFrame({\"precision\": precision, \"recall\": recall})\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local function\n",
    "metric_pr_auc(y, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the best F-1 score\n",
    "metric_pr_f_beta(y= y, probs= probs, beta= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the best F-1 score and give the threshold\n",
    "get_threshold_best_pr_fbeta(y= y, probs= probs, beta= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iso_f_beta() + plot_pr_curve(y, probs, 'red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelisation-Q488yCbE-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
